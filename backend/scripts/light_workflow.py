import requests
import json
import time
import os
from dotenv import load_dotenv

# Carica configurazione
load_dotenv('../.env')

BASE_URL = "http://127.0.0.1:8000/v1"
API_KEY = os.getenv('DEV_API_KEY', 'super-secret-for-local')

headers = {
    "Content-Type": "application/json",
    "X-API-Key": API_KEY
}

def test_step_by_step():
    """Test del workflow RAG step-by-step con controlli di sicurezza"""
    
    print("ğŸ§ª NeuraMind - Workflow Demo Leggero")
    print("=" * 50)
    
    # Step 0: Verifica connessione
    print("ğŸ“¡ Step 0: Verifica connessione server...")
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code != 200:
            print("âŒ Server non raggiungibile")
            return
        print("âœ… Server OK")
    except Exception as e:
        print(f"âŒ Errore connessione: {e}")
        return
    
    print("\n" + "="*50)
    print("ğŸ”„ WORKFLOW RAG - Step by Step")
    print("="*50)
    
    # Step 1: Upsert (molto leggero)
    print("\nğŸ“ Step 1: UPSERT - Salvataggio documento...")
    print("Cosa fa: Converte il testo in embeddings e lo salva in Pinecone")
    
    # Testo molto piccolo per ridurre carico
    document_text = """
    NeuraMind Ã¨ un assistente AI personale.
    Aiuta a gestire documenti e note.
    Utilizza la ricerca semantica.
    """
    
    upsert_data = {
        "user_id": "demo_user",
        "item_id": "demo_doc_001", 
        "title": "Demo Document",
        "text": document_text.strip()
    }
    
    print(f"ğŸ“„ Documento da salvare: {len(document_text)} caratteri")
    print("â³ Invio richiesta a OpenAI per embeddings...")
    
    try:
        start_time = time.time()
        response = requests.post(
            f"{BASE_URL}/embed-upsert", 
            headers=headers, 
            json=upsert_data,
            timeout=30  # Timeout piÃ¹ lungo
        )
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Upsert completato in {elapsed:.2f}s")
            print(f"ğŸ“Š Chunks creati: {len(result.get('ids', []))}")
            print(f"ğŸ†” IDs: {result.get('ids', [])}")
        else:
            print(f"âŒ Upsert fallito: {response.status_code}")
            print(f"Errore: {response.text}")
            return
            
    except requests.exceptions.Timeout:
        print("â° Timeout - L'operazione Ã¨ troppo lenta per questo PC")
        print("ğŸ’¡ Prova con un testo piÃ¹ corto o controlla la connessione internet")
        return
    except Exception as e:
        print(f"âŒ Errore durante upsert: {e}")
        return
    
    # Step 2: Query (piÃ¹ veloce)
    print(f"\nğŸ” Step 2: QUERY - Ricerca semantica...")
    print("Cosa fa: Cerca documenti simili alla domanda")
    
    query_data = {
        "user_id": "demo_user",
        "query": "Cos'Ã¨ NeuraMind?",
        "top_k": 3
    }
    
    print(f"â“ Domanda: {query_data['query']}")
    print("â³ Ricerca in corso...")
    
    try:
        start_time = time.time()
        response = requests.post(
            f"{BASE_URL}/query",
            headers=headers,
            json=query_data,
            timeout=15
        )
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            matches = result.get("matches", [])
            print(f"âœ… Query completata in {elapsed:.2f}s")
            print(f"ğŸ“Š Risultati trovati: {len(matches)}")
            
            for i, match in enumerate(matches):
                score = match.get('score', 0)
                preview = match.get('metadata', {}).get('preview', 'N/A')
                print(f"  {i+1}. Score: {score:.3f} - {preview[:50]}...")
                
        else:
            print(f"âŒ Query fallita: {response.status_code}")
            return
            
    except Exception as e:
        print(f"âŒ Errore durante query: {e}")
        return
    
    # Step 3: Answer (dipende da OpenAI)
    print(f"\nğŸ’¬ Step 3: ANSWER - Generazione risposta AI...")
    print("Cosa fa: GPT genera una risposta basata sui documenti trovati")
    
    answer_data = {
        "query": query_data["query"],
        "contexts": matches[:2]  # Usa solo i primi 2 risultati
    }
    
    print("â³ GPT sta pensando...")
    
    try:
        start_time = time.time()
        response = requests.post(
            f"{BASE_URL}/answer",
            headers=headers,
            json=answer_data,
            timeout=20
        )
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get("answer", "")
            print(f"âœ… Risposta generata in {elapsed:.2f}s")
            print(f"\nğŸ¤– Risposta di NeuraMind:")
            print("-" * 40)
            print(answer)
            print("-" * 40)
        else:
            print(f"âŒ Answer fallito: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Errore durante answer: {e}")
    
    print(f"\nğŸ‰ Workflow RAG completato!")
    print("\nğŸ“š Riepilogo del processo:")
    print("1. ğŸ“ UPSERT: Documento â†’ Embeddings â†’ Pinecone")
    print("2. ğŸ” QUERY: Domanda â†’ Ricerca vettoriale â†’ Risultati")
    print("3. ğŸ’¬ ANSWER: Risultati + Domanda â†’ GPT â†’ Risposta finale")

if __name__ == "__main__":
    test_step_by_step()
